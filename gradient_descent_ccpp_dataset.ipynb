{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a82a70",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b676a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1352f418",
   "metadata": {},
   "source": [
    "# Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac25da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7176, 5)\n",
      "(2392, 4)\n"
     ]
    }
   ],
   "source": [
    "train = np.genfromtxt('./training_ccpp_x_y_train.csv', delimiter=\",\")\n",
    "test = np.genfromtxt('./test_ccpp_x_test.csv', delimiter=\",\")\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7993c6e2",
   "metadata": {},
   "source": [
    "# Preprocessing and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d184bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.47827466e+00, -1.24764165e+00,  1.30221067e+00,\n",
       "         7.58624590e-01],\n",
       "       [ 2.89012041e-01,  3.06797549e-01,  6.61749044e-01,\n",
       "        -4.46921842e-01],\n",
       "       [-3.99975582e-01, -4.21012529e-01, -2.87207194e-01,\n",
       "         3.75010552e-01],\n",
       "       ...,\n",
       "       [ 1.36062192e+00,  1.18048335e+00, -6.54382840e-01,\n",
       "        -5.83682640e-01],\n",
       "       [-4.36097263e-01,  9.29089763e-04,  7.84140927e-01,\n",
       "        -6.59584883e-01],\n",
       "       [ 1.40209496e+00,  6.07960340e-01, -4.31394890e-01,\n",
       "        -1.73110573e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train[: , :-1]\n",
    "y = train[: , -1]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(x)\n",
    "x = scaler.transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7a56cf",
   "metadata": {},
   "source": [
    "# Implementing gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458a4a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x, y, m):\n",
    "    cost = 0 \n",
    "    for i in range(len(x)):\n",
    "        cost += (1/(len(x)))*((y[i]-sum(m*x[i]))**2)\n",
    "    return cost\n",
    "        \n",
    "def step_gradient(x, y, m, learning_rate):\n",
    "    m_slope = np.zeros(len(x[0]))\n",
    "    M = len(x)\n",
    "    for i in range(M):\n",
    "        X = x[i]\n",
    "        Y = y[i]\n",
    "        for j in range(len(X)):\n",
    "            m_slope[j] += (-2/M)*(Y-sum(m*X))*(X[j])\n",
    "#     print(m_slope)\n",
    "    new_m = m - (learning_rate*m_slope)\n",
    "    return new_m\n",
    "\n",
    "def gd(x, y, learning_rate, number_of_iter):\n",
    "    m = np.zeros(len(x[0]))\n",
    "    for i in range(number_of_iter):\n",
    "        m = step_gradient(x, y, m, learning_rate)\n",
    "        print(\"iteration\", i, \" \", cost(x, y, m))\n",
    "    return m \n",
    "\n",
    "def gradient_descent(x, y):\n",
    "    learning_rate = 0.35\n",
    "    number_of_iter = 100\n",
    "    x = np.append(x, np.ones(len(x)).reshape(-1, 1), axis=1)\n",
    "    m = gd(x, y, learning_rate, number_of_iter)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab30af",
   "metadata": {},
   "source": [
    "# Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14c785a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0   18746.02651010732\n",
      "iteration 1   1766.8066063688912\n",
      "iteration 2   211.14167087414796\n",
      "iteration 3   56.95576326493632\n",
      "iteration 4   35.63911811652189\n",
      "iteration 5   29.70538304469621\n",
      "iteration 6   26.915995522679363\n",
      "iteration 7   25.32814618695703\n",
      "iteration 8   24.339144656950022\n",
      "iteration 9   23.675325116258644\n",
      "iteration 10   23.198090719847613\n",
      "iteration 11   22.83462055634631\n",
      "iteration 12   22.545462539383276\n",
      "iteration 13   22.30836449727373\n",
      "iteration 14   22.110082796897142\n",
      "iteration 15   21.942202452085393\n",
      "iteration 16   21.798986770874226\n",
      "iteration 17   21.676257458867614\n",
      "iteration 18   21.5708001193456\n",
      "iteration 19   21.480039329682675\n",
      "iteration 20   21.401853421210365\n",
      "iteration 21   21.33446281423798\n",
      "iteration 22   21.276358045579634\n",
      "iteration 23   21.226250012096965\n",
      "iteration 24   21.18303329198881\n",
      "iteration 25   21.14575766593341\n",
      "iteration 26   21.11360515144266\n",
      "iteration 27   21.08587100300165\n",
      "iteration 28   21.061947733096268\n",
      "iteration 29   21.04131153649423\n",
      "iteration 30   21.02351068499799\n",
      "iteration 31   21.00815556997896\n",
      "iteration 32   20.994910139987375\n",
      "iteration 33   20.983484528436815\n",
      "iteration 34   20.973628701108293\n",
      "iteration 35   20.965126979936926\n",
      "iteration 36   20.957793320962505\n",
      "iteration 37   20.951467241943813\n",
      "iteration 38   20.946010309940572\n",
      "iteration 39   20.941303111699582\n",
      "iteration 40   20.93724264040099\n",
      "iteration 41   20.933740041500425\n",
      "iteration 42   20.930718668302074\n",
      "iteration 43   20.928112404695085\n",
      "iteration 44   20.92586421833692\n",
      "iteration 45   20.923924912621313\n",
      "iteration 46   20.922252050116846\n",
      "iteration 47   20.920809023915282\n",
      "iteration 48   20.919564256569814\n",
      "iteration 49   20.918490509091754\n",
      "iteration 50   20.917564284885287\n",
      "iteration 51   20.916765315576107\n",
      "iteration 52   20.916076117483122\n",
      "iteration 53   20.915481609025598\n",
      "iteration 54   20.914968780697127\n",
      "iteration 55   20.914526410380855\n",
      "iteration 56   20.914144817777753\n",
      "iteration 57   20.913815652575096\n",
      "iteration 58   20.913531711718626\n",
      "iteration 59   20.91328678178871\n",
      "iteration 60   20.91307550303407\n",
      "iteration 61   20.912893252084995\n",
      "iteration 62   20.912736040781493\n",
      "iteration 63   20.912600428900905\n",
      "iteration 64   20.912483448876134\n",
      "iteration 65   20.912382540857312\n",
      "iteration 66   20.91229549669531\n",
      "iteration 67   20.91222041162021\n",
      "iteration 68   20.912155642560897\n",
      "iteration 69   20.91209977218932\n",
      "iteration 70   20.912051577905668\n",
      "iteration 71   20.91201000508422\n",
      "iteration 72   20.911974143995405\n",
      "iteration 73   20.91194320989868\n",
      "iteration 74   20.91191652586932\n",
      "iteration 75   20.91189350798617\n",
      "iteration 76   20.9118736525536\n",
      "iteration 77   20.91185652507957\n",
      "iteration 78   20.911841750766616\n",
      "iteration 79   20.911829006311905\n",
      "iteration 80   20.911818012830977\n",
      "iteration 81   20.911808529755472\n",
      "iteration 82   20.911800349569702\n",
      "iteration 83   20.91179329326797\n",
      "iteration 84   20.91178720643873\n",
      "iteration 85   20.911781955885388\n",
      "iteration 86   20.9117774267109\n",
      "iteration 87   20.911773519804438\n",
      "iteration 88   20.911770149671668\n",
      "iteration 89   20.91176724256507\n",
      "iteration 90   20.911764734868758\n",
      "iteration 91   20.911762571707488\n",
      "iteration 92   20.911760705745188\n",
      "iteration 93   20.91175909614923\n",
      "iteration 94   20.911757707697483\n",
      "iteration 95   20.911756510006423\n",
      "iteration 96   20.91175547686748\n",
      "iteration 97   20.91175458567252\n",
      "iteration 98   20.911753816919852\n",
      "iteration 99   20.91175315378679\n"
     ]
    }
   ],
   "source": [
    "m = gradient_descent(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e30047",
   "metadata": {},
   "source": [
    "# Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52747a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([469.95815235, 471.76676052, 433.85480447, ..., 439.13979258,\n",
       "       450.66436422, 447.27468095])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = test[:, :]\n",
    "x = scaler.transform(x)\n",
    "x = np.append(x, np.ones(len(x)).reshape(-1, 1), axis=1)\n",
    "y_pred = []\n",
    "for i in x:\n",
    "    y_pred.append(sum(m*i))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b897c6b",
   "metadata": {},
   "source": [
    "# Saving the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6bd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predictions.csv', y_pred, delimiter=',', fmt=\"%.5f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
